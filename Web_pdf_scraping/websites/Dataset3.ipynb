{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AbLcrTWHuqkW"
      },
      "outputs": [],
      "source": [
        "#install libraries\n",
        "!pip install requests\n",
        "!pip install html5lib\n",
        "!pip install bs4\n",
        "!pip install beautifulsoup4==4.9.3\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import libraries\n",
        "import requests\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup"
      ],
      "metadata": {
        "id": "LZ9xHryrvEB4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#input the link to the website to extract its contents\n",
        "url = \"https://www.theguardian.com/society/2018/dec/16/alzheimers-dementia-cure-virtual-reality-navigation-skills\"\n",
        "response = requests.get(url)\n",
        "soup = BeautifulSoup(response.text, \"html5lib\")\n",
        "print(response.status_code)\n",
        "print(soup.prettify())\n"
      ],
      "metadata": {
        "id": "3dxnE3wpvFuL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#find the p tags that needs to be scraped\n",
        "summary = soup.find_all(\"p\",  attrs = {'class': 'dcr-4cudl2'})\n",
        "summary"
      ],
      "metadata": {
        "id": "moI2SfWHvIWa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#get the text from the p tags and store them in a list\n",
        "sentence_list = []\n",
        "for sentence in summary:\n",
        "  text = sentence.get_text(strip = True)\n",
        "  sentence_list.append(text)\n",
        "  print(text)\n",
        "\n",
        "len(sentence_list)\n"
      ],
      "metadata": {
        "id": "HaPQ6HrKvKau"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#convert the list to a dataframe\n",
        "df = pd.DataFrame(sentence_list, columns = ['Text'])\n",
        "df"
      ],
      "metadata": {
        "id": "DQ0jNR3EvMg2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#store to a csv file\n",
        "df.to_csv(\"Dataset3\")"
      ],
      "metadata": {
        "id": "DWdER3jQvQAn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}