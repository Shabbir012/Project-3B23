{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B1QzR9D6wJWy"
      },
      "outputs": [],
      "source": [
        "#install libraries\n",
        "!pip install requests\n",
        "!pip install html5lib\n",
        "!pip install bs4\n",
        "!pip install beautifulsoup4==4.9.3\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import libraries\n",
        "import requests\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup"
      ],
      "metadata": {
        "id": "2nRe-l0UweDD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#input the link to the website to extract its contents\n",
        "url = \"https://www.pewresearch.org/internet/2022/06/30/the-metaverse-in-2040/\"\n",
        "response = requests.get(url)\n",
        "soup = BeautifulSoup(response.text, \"html5lib\")\n",
        "print(response.status_code)\n",
        "print(soup.prettify())\n"
      ],
      "metadata": {
        "id": "aIpj_23YwgbR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#find the p tags that needs to be scraped\n",
        "summary = soup.find_all(\"p\")\n",
        "summary"
      ],
      "metadata": {
        "id": "BO6SjA8CxYU3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#get the text from the p tags and store them in a list\n",
        "sentence_list = []\n",
        "for sentence in summary:\n",
        "  text = sentence.get_text(strip = True)\n",
        "  sentence_list.append(text)\n",
        "  print(text)\n",
        "\n",
        "len(sentence_list)\n"
      ],
      "metadata": {
        "id": "oyVuJYbMxtlF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#convert the list to a dataframe\n",
        "df = pd.DataFrame(sentence_list, columns = ['Text'])\n",
        "df\n"
      ],
      "metadata": {
        "id": "RoW3aYm3x0Lt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#drop irrelevent information\n",
        "df = df.drop([0, 1, 2, 3, 4, 42, 43, 44, 45, 46,47, 48, 49, 50, 51, 52])\n",
        "df"
      ],
      "metadata": {
        "id": "iSOUYU6rzPPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#store to a csv file\n",
        "df.to_csv(\"Dataset18\")"
      ],
      "metadata": {
        "id": "OHdQVb160uOt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}