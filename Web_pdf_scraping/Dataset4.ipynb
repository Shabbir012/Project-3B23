{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kcC_K9tph_j3"
      },
      "outputs": [],
      "source": [
        "#install the libraries\n",
        "!pip install requests\n",
        "!pip install html5lib\n",
        "!pip install bs4\n",
        "!pip install beautifulsoup4==4.9.3\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import the libraries\n",
        "import requests\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup"
      ],
      "metadata": {
        "id": "t4VG9nIdiFDO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#scraping the content from the website and storing the paragraphs to the list\n",
        "datas = []\n",
        "data = []\n",
        "pages = [1, 2, 3, 9]\n",
        "\n",
        "for i in range(1,11):\n",
        "  url = f\"https://www.bbc.co.uk/search?q=metaverse&d=NEWS_PS&seqId=079eed50-d614-11ee-b992-d552599cab14&page={i}\"\n",
        "  response = requests.get(url)\n",
        "  soup = BeautifulSoup(response.text, \"html5lib\")\n",
        "  articles = soup.find_all('div', attrs={'class': 'ssrcss-1f3bvyz-Stack'})\n",
        "\n",
        "  for article in articles:\n",
        "    # ... (rest of the code to find link)\n",
        "    links = article.find(\"a\", attrs={'class': 'ssrcss-its5xf-PromoLink'})\n",
        "    link = links.get('href')\n",
        "\n",
        "    # Check if link already exists before processing\n",
        "    if link and link not in data:\n",
        "      data.append(link)  # Add unique link to data list\n",
        "\n",
        "# Process links outside the loop (avoid duplicates)\n",
        "for link in data:\n",
        "  link_response = requests.get(link)\n",
        "  link_soup = BeautifulSoup(link_response.text, \"html5lib\")\n",
        "  summary = link_soup.find_all(\"div\", attrs={'class': 'ssrcss-7uxr49-RichTextContainer'})\n",
        "  headline = link_soup.find(\"h1\",attrs = {'class': 'ssrcss-fmi64d-StyledHeading'})\n",
        "  for sentence in summary:\n",
        "      text = sentence.get_text(strip = True)\n",
        "      datas.append(text)\n",
        "len(datas)\n"
      ],
      "metadata": {
        "id": "3ShwAdqCUeEM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#convert it to a dataframe\n",
        "df = pd.DataFrame(datas, columns = ['Text'])\n",
        "df.head(5)"
      ],
      "metadata": {
        "id": "nJz7CkQ4qQ3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#store in csv file\n",
        "df.to_csv(\"Dataset4\")"
      ],
      "metadata": {
        "id": "5YnrhEMBCa4g"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}